\chapter{Results and Discussion}
\label{cha:result}
In this section we apply techniques introduced in \cref{cha:methodology} to test our new methods for nefarious router classification. We present results of nefarious router classification under assumption sets one, two, and three (in \cref{ssec:Ras1,ssec:Ras2,ssec:Ras3} respectively). We summarise our findings and comparisons between classifiers in \cref{ssec:Rnefidsummary}. Comparisons focus on classifiers two and three, as classifier one uses delay distributions not obtainable with network tomography.\par
In \cref{sec:Rprobingoptimality} we present results from testing of candidate optimisation to probe allocation and metric normalisation. Additionally, in \cref{ssec:Rloweraccuracybounds}, we calculate the lower bound on the accuracy of each probe allocation scheme for each topology, comparing this to results seen in experimental analysis. Validation of model correctness with respect to assumptions regarding queue length stabilisation (noted as a requirement in previous work) is presented in Appendix A.

\section{Identifying Nefarious Behaviour}
\label{sec:Rnefarouterdetection}
For numerical analysis of classification under our three proposed assumption sets, we consider the Nobel, Free, and CPLEX network topologies. This allows us to provide a robust analysis of analytical results using confusion matrices for each classification scenario. For each assumption set, we discuss the classifiers' performance under each scenario and provide generalised evaluations of each classifier. ROC curves show classifier performance over a range of true positive rates (TPRs) and false positive rates (FPRS), as the blue stepped line. The expected performance of a random classifier is also shown for comparison as a dashed orange line.\par
We note that ROC curves are presented with true positive rates to adhere to best practise, however, for the sake of concision we refer to this as sensitivity when discussing results. To pair with this discussion of sensitivity we also discuss the specificity of each classier. Although not explicit shown in ROC curves this is analogous to the true negative rate ($1-FPR$). We begin with assumption set one.

\subsection{Classifier One}
\label{ssec:Ras1}
Firstly we consider classification with a full delay distribution and baseline comparisons. Confusion matrices for router classification are shown in \cref{tab:ngercmatrix,tbl:frncecmatrix,tbl:nrwycmatrix}. 
\begin{table}[H]
    \centering
    \aboverulesep = 0pt
    \belowrulesep = 0pt
    \begin{tabular}{l|cc}
        {\backslashbox{\textit{Actual}}{\textit{Predicted}}} & {Nefarious} & {Non-nefarious}\\
        \midrule
        {Nefarious}     & 1807  & 0     \\
        {Non-nefarious} & 37    & 3018  \\
    \end{tabular}
    \caption{Confusion matrix for classification under assumption set 1 in Nobel.}
    \label{tab:ngercmatrix}
\end{table}
\begin{table}[H]
    \centering
    \aboverulesep = 0pt
    \belowrulesep = 0pt
    \begin{tabular}{l|cc}
        {\backslashbox{\textit{Actual}}{\textit{Predicted}}} & {Nefarious} & {Non-nefarious}\\
        \midrule
        {Nefarious}     & 2781  & 101     \\
        {Non-nefarious} & 101    & 2658  \\
    \end{tabular}
    \caption{Confusion matrix for classification under assumption set 1 in Free.}
    \label{tbl:frncecmatrix}
\end{table}
\begin{table}[H]
    \centering
    \aboverulesep = 0pt
    \belowrulesep = 0pt
    \begin{tabular}{l|cc}
        {\backslashbox{\textit{Actual}}{\textit{Predicted}}} & {Nefarious} & {Non-nefarious}\\
        \midrule
        {Nefarious}     & 1905  & 46     \\
        {Non-nefarious} & 413   & 1896   \\
    \end{tabular}
    \caption{Confusion matrix for classification under assumption set 1 in CPLEX.}
    \label{tbl:nrwycmatrix}
\end{table}
Each classification was performed using a KS comparison against the true baseline values and a p-val cut-off of 0.0 to provide the strictest possible guarantee of significance. We present a summary of classification sensitivity and specificity in \cref{tbl:Rassumptionset1summary}, discussing the results in more detail below.\par
Classification in the Nobel topology has a sensitivity of 100\% across all evaluated sets of nefarious routers. With 37 false positives, the classifier has a specificity of 99.99\%, giving an extremely precise and accurate nefarious router classification. For the Free and CPLEX topologies, we observe marginally worse classification performance. The classifier has a sensitivity of 96.5\% and 97.64\% and a specificity of 96.34\% and 82.11\% for Free and CPLEX respectively. Therefore, classification in each topology easily meets the 0.9 sensitivity threshold for scenario one.\par
For scenario two, the classifier fulfils the requirements over each topology, achieving a true positive rate >> 0.7. The highest false positive rate occurs in the CPLEX topology where a rate of 0.18 is achieved. Similarly, the classifier meets requirement in scenario three in all topologies. The highest false positive rate occurs in the CPLEX topology at only 0.02.\par
However, the most striking result is a sensitivity of 100\% in the Nobel topology, closely followed by the 99.9\% specificity in the same topology. We anticipate that the extreme efficacy of this classification is due to the relatively small number of routers within the Nobel topology, allowing us to obtain router identifiability using only 28 probe paths.\par
The larger size, and therefore complexity, of the network means that router queue buffer metrics have more noise. This is due to the number of paths background traffic can take between switches exponentially increasing with network size. In combination with the stochastic routing behaviour, this results in increased noise in the measurements of each router's PDA. We would, however, expect the true sensitivity of the classifier to be <100\% though the sample size needed to determine this would be prohibitively large.\par
\begin{table}[t]
    \centering
    \begin{tabular}{ccc}
        Topology & Sensitivity & Specificity\\
        \midrule
        Nobel & 100   & 99.99 \\
        Free  & 96.5  & 97.64 \\
        CPLEX & 96.34 & 82.11 \\
    \end{tabular}
    \caption{Summary of classification sensitivity and specificity for classifier 1.}
    \label{tbl:Rassumptionset1summary}
\end{table}
In all topologies, we observe the classifier having a higher sensitivity than specificity. This is likely due to the stochastic routing behaviour of the network routing packets away from nefarious routers that have larger buffer queues. This would cause non-nefarious routers to receive more packets, and consequently a larger buffer queue to appear nefarious. Nefarious routers, however, even when forwarded few packets, will still delay a proportion of these packets. These routers will therefore maintain a larger queue length, enabling their classification from packet delay metrics and minimising false negatives.\par

\subsection{Classifier Two}
\label{ssec:Ras2}
Next we consider classification with a baseline comparison and only packet delay summary statics available. ROC curves for classification in each topology are given in \cref{fig:RA2ROCcurves}. Note that the performance of the classifier, under each scenario we use for quantitative comparison (see \cref{ssec:MInferredvalues}), is extrapolated from a corresponding point on the ROC curve. We present a summary of these results in \cref{tbl:Rassumptionset2summary} where FNR and FPR, respectively, correspond to the closest false negative rate and false positive rate which meet each scenarios requirements.\par
For scenario one, router classification in the Nobel, Free, and CPLEX topologies satisfied the sensitivity threshold of 0.9 with false positive rates of 0.811, 0.838, and 0.919 respectively. Classification in the Nobel and Free topologies is superior to random classification of routers. However, with a sensitivity of > 0.763, the classification accuracy for the CPLEX network is inferior to random classification.\par This is due to a sympathetic increase between non-nefarious router PDA (over baseline PDA) and nefarious router PDA. The sympathetic increase is caused by the link-state protocol routing packets around nefarious routers as their buffer queues fill. This results in more packets being forwarded to non-nefarious routers over the baseline simulation, thus increasing the difference in PDA from the baseline simulation.\par
For scenario two, the classifier reaches the 0.7 sensitivity threshold in the Nobel and Free within the specificity requirement. However, in the CPLEX topology, the specificity requirement is not and the classifier can only achieve a false positive rate
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/nobel-germany_case2_roc.png}
        \caption{Nobel Topology.}
    \end{subfigure}
    \begin{subfigure}{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/france_case2_roc.png}
        \caption{Free Topology.}
    \end{subfigure}
    \begin{subfigure}{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/norway_case2_roc.png}
        \caption{CPLEX Topology.}
    \end{subfigure}
    \caption{ROC curves for classification under assumption set 2.}
    \label{fig:RA2ROCcurves}
\end{figure}
of 0.669. For scenario three the 0.9 specificity threshold is satisfied with false negative rates of 0.558, 0.682, and 0.864 for each topology respectively.\par
In scenario two all classifier perform better than a random classification. However classification in the CPLEX topology is notably worse than the Nobel and Free topologies, even when accounting for the increased number of routers. We anticipate this is caused by the same factors as in classifier one. In general though, the less stringent sensitivity requirements can be seen to reduce the impact of noise on classification.\par
In scenario three, as in scenario two, all classifier perform better than a random classification. However, with scenario three's requirements on specificity, the reduction in classifier accuracy is proportional to the number of routers in each topology. Additionally, across all topologies, the classifier performs the best relative to a random classification in sensitivity and specificity ranges of [0.2, 0.76] and [0.24, 0.83] respectively. Classification under assumption case two is therefore better suited to use in cases with a higher tolerance for false negatives.\par
\begin{table}[t]
    \centering
    \begin{tabular}{ccccccc}
        & \multicolumn{2}{c}{Scenario 1} & \multicolumn{2}{c}{Scenario 2} & \multicolumn{2}{c}{Scenario 3}\\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
        Topology & TPR & FPR & TPR & FPR & TPR & FPR\\
        \midrule
        Nobel & 0.9 & 0.811 & 0.7   & 0.558 & 0.442 & 0.1 \\
        Free  & 0.9 & 0.838 & 0.7   & 0.682 & 0.318 & 0.093 \\
        CPLEX & 0.9 & 0.919 & 0.669 & 0.864 & 0.154 & 0.098 \\
    \end{tabular}
    \caption{Summary of performance under each scenario (see \cref{ssec:MInferredvalues}) for classifier 2.}
    \label{tbl:Rassumptionset2summary}
\end{table}
\noindent

\subsection{Classifier Three}
\label{ssec:Ras3}
\noindent
\begin{figure}
    \centering
    \begin{subfigure}{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/nobel-germany_case3_roc.png}
        \caption{Nobel Topology.}
    \end{subfigure}
    \begin{subfigure}{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/france_case3_roc.png}
        \caption{Free Topology.}
    \end{subfigure}
    \begin{subfigure}{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/norway_case3_roc.png}
        \caption{CPLEX Topology.}
    \end{subfigure}
    \caption{ROC curves for classification under assumption set 3.}
    \label{fig:RA3ROCcurves}
\end{figure}
Finally, we use only packet delay summary statics for classification. ROC curves for classification in each topology are given in \cref{fig:RA3ROCcurves}. We evaluate the classifiers' performance for each scenario below. Additionally, as in our evaluation of classifier two, We present a summary of these results in \cref{tbl:Rassumptionset3summary} where FNR and FPR, respectively, correspond to the closest false negative rate and false positive rate which meet each scenarios requirements.\par\par
For scenario one, classification of the Nobel and CPLEX topologies results in false positive rates of 0.4 and 0.5 respectively. For the Free topology, the classifier is only able to attain a sensitivity of 0.9 with a false positive rate of 1.0 (classifying all routers as nefarious). Excluding this case, PDA is not sufficient to classify routers with a sensitivity greater than 0.83 in the Free topology.\par
This is due to the topology containing a router with a degree of 10. This router represents the city of Paris (see \cref{fig:MISPplots}), we will therefore refer to it as \textit{the Paris router} onwards. The Paris router experiences more than twice as much traffic as the average router of degree 3. and thus has a near or completely full queue buffer regardless of nefarious behaviour. This is compounded by 15 of the 37 probe paths including Paris, resulting in a disproportionate number of probe packets traversing the router. Therefore, when using a PDA threshold equal to the buffer queue length $\pm0.1$ for classification, the Paris router is always classified as nefarious. A similar limitation exists in the CPLEX topology, where due to the same factors, a maximum sensitivity of 0.966 can be achieved.\par
Conversely, the classifier performs extremely well on the Nobel topology achieving a true positive rate of 1.0 with a false positive rate of 0.544. Although both Nobel and CPLEX have a maximum router degree of 6, in the Nobel network only 12 probe paths traverse the maximally connected router, compared to 21 in CPLEX. Therefore, in the CPLEX network (unlike the Free network), the maximally connected router's buffer queue receives disproportionately more probe packets. This results in the router being classified as nefarious, regardless of its delaying behaviour, in the majority of test trials.\par
\begin{table}[t]
    \centering
    \begin{tabular}{ccccccc}
        & \multicolumn{2}{c}{Scenario 1} & \multicolumn{2}{c}{Scenario 2} & \multicolumn{2}{c}{Scenario 3}\\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
        Topology & TPR & FPR & TPR & FPR & TPR & FPR\\
        \midrule
        Nobel & 0.9 & 0.4  & 0.7 & 0.339 & 0.371 & 0.1 \\
        Free  & 0.9 & 0.5  & 0.7 & 0.363 & 0.371 & 0.1 \\
        CPLEX & 1.0 & 0.83 & 0.7 & 0.235 & 0.444 & 0.1 \\
    \end{tabular}
    \caption{Summary of performance under each scenario (see \cref{ssec:MInferredvalues}) for classifier 3.}
    \label{tbl:Rassumptionset3summary}
\end{table}
For scenario two, classification of all topologies meets specificity and sensitivity requirements. Classification in the Nobel, Free, and CPLEX topologies at the false negative threshold have false positive rates of 0.339, 0.363, and 0.235 respectively. These rates are a strict improvement over those from classifier two. This improvement is due to the increased queue length of nefarious routers causing traffic to be re-routed through non-nefarious routers, thereby increasing their queue lengths. As this sympathetic increase is absent in the baseline simulation, an increase in PDA is seen from the baseline of non-nefarious routers’. This increase is indistinguishable from the buffer queue increase in nefarious routers. Therefore, we observe more cases of routers being incorrectly labelled as nefarious.\par
For scenario three, classification of each topology results in a false negative rate of 0.629 for the Nobel and Free topologies and 0.556 for CPLEX. However, for each case in \cref{fig:RA3ROCcurves}, no PDA thresholds enable a classification with a false positive rate < 0.2. This is due to an overlap in PDA values between weakly connected nefarious routers and strongly connected non-nefarious routers. The amount of traffic arriving at strongly connected non-nefarious routers fills their buffer queue at a rate similar to that of a less connected nefarious router. Therefore, any PDA threshold sufficient to identify any weakly connected nefarious routers, will incorrectly label strongly connected non-nefarious routers.\par
We note that as the PDA of each router is dependant on it's queue buffer length, the accuracy of this classifier would suffer severely in network with heterogeneous router buffer queue lengths. The assumption around router homogeneity is however reasonable as for at-scale data center and ISP networks environments homogeneity is maintained. Although, for smaller scale at ad hoc home hobby networks or IoT networks where heterogeneity in networking components is far more likely this could present an issue. 

\subsection{Summary of Comparisons}
\label{ssec:Rnefidsummary}
In this section we have analysed three nefarious router classifiers, using three real-world use cases for a fair comparison of performance. Classifier one was found to have the best performance in each use case. This classifier achieved a near perfect accuracy across all investigated topologies. However, as this underlying distribution can not be obtained via network tomography, we focused our comparison on the second and third classifiers.\par
Classifier two was found to perform better than a random classification in all cases other than in the CPLEX topology with a sensitivity > 0.763. This was caused by a sympathetic increase, due to stochastic traffic routing, between non-nefarious router PDA (over baseline PDA) and nefarious router PDA. This classifier performed optimally for specificity requirements between 0.24 and 0.83 across all topologies.\par
Classifier three achieved greater accuracy than classifier two for sensitivity and specificity requirements of [0.2, 0.83] and [0.46, 0.75] respectively. This was due to absence of baseline comparisons, the absence prevented sympathetic increases between routers from impacting classification. However, classifier two performed very poorly for sensitivities below 0.2 and above 0.8. This was likely due to an overlap in PDA metrics between strongly connected non-nefarious and weakly connected nefarious.

\section{Optimisation Impacts}
\label{sec:Rprobingoptimality}
In this section we apply optimisations to the allocation of probe packets between probe paths, and to metrics collected from this probing. Classification resulting from these candidate optimisations are compared and contrasted to original measures so as to quantify their impact.\par
In \cref{ssec:Rprobeallocation} we present ROC curves to evaluate performance of classifiers two and three, using a proportional probe allocation (PPA) (see \cref{ssec:Mprobeallocation}). We discuss the performance of each classifier for each real-world topology. In \cref{ssec:Rloweraccuracybounds} we then compute the CRB for each probe allocation scheme in each topology. The CRB bounds are then compared to ROC curves for both probing schemes in each topology. Additionally, we contrast the CRB for each topology, discussing the impact of the number of routers in each network on this lower accuracy bound.\par
In \cref{ssec:Rmetricnormilisation} we present results from classification with each router's PDA normalised with respect to the router's degree. The produced ROC curves for classifiers two and three in each topology are compared to baseline results without this normalisation.

\subsection{Proportional Probe Allocation}
\label{ssec:Rprobeallocation}
In \cref{fig:RprobeoptROCcurves} we present results from classification, with PDA inferred from network tomography. Sub-figures (a), (c), and (e) correspond to classifier two, while sub-figures (b), (d), and (f) correspond to classifier three. Classifier one is not included in our analysis here, as the information it requires cannot be obtained via network tomography. In each sub-figure a ROC curve showing classification accuracy is provided for both unoptimised and optimised probe allocation over probe paths.\par
Using a two-sample Kolmogorov–Smirnov test we evaluate the distribution of true positives for each classifier in each topology, results are shown in \cref{tbl:Roptkstest}. Given our average is taken over 50 simulations we select an generally accepted p-value of 0.05 to indicate a significant improvement. From this we can reject the null hypothesis of the sensitivity distribution under an equal probe allocation compared to PPA for classifier two, in the Nobel and CPLEX topologies, and classifier three in 
\begin{figure}[H]
    \centering
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/nobel-germany_ac2_opt.png}
        \caption{Nobel topology with classifier 2.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/nobel-germany_ac3_opt.png}
        \caption{Nobel topology with classifier 3.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/france_ac2_opt.png}
        \caption{Free topology with classifier 2.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/france_ac3_opt.png}
        \caption{Free topology with classifier 3.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/norway_ac2_opt.png}
        \caption{CPLEX topology with classifier 2.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/norway_ac3_opt.png}
        \caption{CPLEX topology with classifier 3.}
    \end{subfigure}
    \caption{ROC curves for optimised classification using PPA.}
    \label{fig:RprobeoptROCcurves}
\end{figure}
the Nobel topology. In each of these topologies, use of PPA resulted in a mean sensitivity improvement of 0.214, 0.1, and 0.204 respectively (over all false positive rates).\par
This means that, for any maximal tolerance of false positive, we are on average able to correctly classify 17\% more nefarious routers using network tomography with PPA. Note that improvements can also be seen in sub-figure (f), where PPA enables classification with a minimum false positive rate of 5\%, compared to only 50\% without optimisation. This is, however, not reflected in p-value test results as the comparison is only computed for sensitivity.\par
\begin{table}[t]
 \centering
  \begin{tabular}{@{}ccc@{}}
   \toprule
   &\multicolumn{2}{c}{KS test P-value}\\
   \cmidrule(lr){2-3}
    Topology & Classifier 2 & Classifier 3 \\
    \midrule
    Nobel & 1.08e-06 & 0\\
    Free  & 0.619 & 0.280\\
    CPLEX & 4.31e-57 & 1.00\\
   \bottomrule
  \end{tabular}
  \caption{KS tests of false positive rate distribution with and without PPA.}
  \label{tbl:Roptkstest}
\end{table}
This improvement in classifier performance with PPA for the Nobel and CPLEX topologies is due to the variation of routers between probe paths. For both the Nobel and CPLEX topologies, a single router is present in at most 25\% of paths. However, in the Free topology, a single router is present in at most 47\% of probe paths. This means that, with a proportion allocation, this singular router in the Free topology receives disproportionately more packets. Many of these additional probe packets are dropped due to the limited queue buffer, resulting in only minor changes in classification accuracy from the PPA.\par
In sub-figure (a), for false positive rates < 0.5 classification with unoptimised probe allocation is worse than random. This result is unlikely to be due to noise, as it has been averaged over many simulation runs. We speculate that this poor classification is potentially due to the buffers of nefarious routers being comprised solely of probe packets. This could potentially be caused by traffic re-routing around these nefarious routers. PDA measurements would therefore be far lower than would be expected in the scenario where background traffic was also being forwarded to these routers. However, additional investigation into this behaviour is required to form a substantiated explanation.

\subsection{Cramér–Rao Bounds}
\label{ssec:Rloweraccuracybounds}
Results from analytical calculation of the CBR, given probe paths and probe allocation for each topology, are given in \cref{tbl:crbs}. In each case the CRB is extremely low. This is due to the large number of probe paths used in tomography for each topology. However, as this only represents a lower bound, we focus on comparison of the CRB between topologies and on each probe allocation scheme in a topology.\par
For both probe allocations, network tomography in the Nobel topology has the highest CRB. Network tomography the in the Free and CPLEX topologies was calculated to have the second highest and lowest CRB respectively. This corresponds to classifier accuracy evaluation from ROC curves of each classifier in \cref{fig:RprobeoptROCcurves}. This decrease in accuracy is proportional to the increase in number of routers in each topology. This is due to the additional probe paths, required to uniquely identify each router, reducing the number of measurements we are able to take over each path.\par
However, under PPA probing, the larger CPLEX network has a higher CRB than the Free network. This is due to the Free topology containing a router with a degree of ten, which a disproportionate number of probe paths traverse. Under PPA more probe packets are sent to this router, causing more to be dropped as its buffer queue is already at capacity. These dropped probe packets are the cause of this decrease in the lower accuracy bound.\par
Comparing probing schemes within topologies, the CRB of network tomography with PPA is greater, for each topology, than that an unoptimised probe allocation. The improvement in accuracy of network tomography in the Nobel and CPLEX topologies is 153.03\% and 190.66\%. However, for the Free topology, the improvement is only 29.43\%.\par
\begin{table}[t]
 \centering
  \begin{tabular}{@{}ccc@{}}
   \toprule
    &\multicolumn{2}{c}{\textbf{Probe Allocation}}\\
    \cmidrule(rl){2-3}
    Topology & Unoptimised & PPA \\
    \midrule
    Nobel & 3.18e-05 & 2.39e-04\\
    Free & 1.42e-06 & 1.91e-06\\
    CPLEX & 1.94e-07 & 8.11e-06\\
   \bottomrule
  \end{tabular}
  \caption{Calculated Cramér–Rao bound for each topology and probe allocation}
  \label{tbl:crbs}
\end{table}
This is consistent with ROC curves in \cref{fig:RprobeoptROCcurves}, where a significant improvement in classification was observed for the Nobel and CPLEX topologies. Additionally, the smaller difference in CRB between probe allocation schemes for the Free topology corresponds with classifier performance, where the smallest difference between probe allocation schemes was observed.\par


\subsection{Metric Normalisation}
\label{ssec:Rmetricnormilisation}
ROC curves for nefarious router classification with PDA, normalised with respect to router degree, are shown in \cref{fig:RmetricnormROCcurves}. We omit classifier one, as it does not use PDA for classification. For classifier two, a decrease in accuracy across all true and false positives rates is seen. Similarly, for classifier three, an equal or lesser accuracy over all topologies is seen.\par
The general decrease in classification accuracy is likely due to a router's degree being a poor representation of the number of packets it receives each timestep. Other contributing factors, such as the routing tables of surrounding routers and their respective degree, would also likely need to be accounted for. It is also possible that
\begin{figure}[H]
    \centering
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/metric_normilisation/nobel-germany_ac2.png}
        \caption{Nobel Topology Classifier 2.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/metric_normilisation/nobel-germany_ac3.png}
        \caption{Nobel Topology Classifier 3.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/metric_normilisation/france_ac2.png}
        \caption{Free Topology Classifier 2.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/metric_normilisation/france_ac3.png}
        \caption{Free Topology Classifier 3.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/metric_normilisation/norway_ac2.png}
        \caption{CPLEX Topology Classifier 2.}
    \end{subfigure}
    \begin{subfigure}[H]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/results/metric_normilisation/norway_ac3.png}
        \caption{CPLEX Topology Classifier 3.}
    \end{subfigure}
    \caption{ROC curves for classification with PDA normalisation.}
    \label{fig:RmetricnormROCcurves}
\end{figure}
the contributions of incoming traffic and nefarious delaying to a router's queue length are intrinsically related.\par
This would mean that attempts to account for incoming traffic contributions so as to better identify nefarious delaying are unlikely to yield classification improvements, irrespective of the number of factors accounted for relating to incoming traffic volume. We therefore highlight, as an area for future research, methods of distinguishing between incoming traffic, and other factors which contribute to a router's buffer queue size. Such distinguishing would enable us to better identify nefarious delaying behaviour.\par

\section{Summary}
In this chapter we have presented experimental results of three classifiers of nefarious router behaviour in three real-world ISP topologies. The efficacy of each classifier was discussed and comparisons between each classifier were made. Classifier one was found to be the most effective. Confusion matrices for classifier one's performance on each topology were presented and a small decrease in classifier performance was seen for topologies with more routers.\par
For classifier two and three, ROC curves were produced, varying the threshold for a router to be labelled as nefarious. Three use cases (see \cref{ssec:MInferredvalues}) corresponding to the upper left, middle, and lower right segments of the ROC curve were used to compare classifiers two and three. These three segments of the ROC curve correspond to varying specificity and sensitivity requirements.\par
Classifier two was found to be more effective than classifier three at identifying nefarious routers when a high specificity or sensitivity was required. This was because the comparison to baseline router metrics used allowed for a finer grained distinction of router performance to be made. In contrast, classifier three was unable to distinguish between nefarious and non-nefarious routers with a very high specificity or sensitivity. This inability was due to overlap in the PDA of strongly connected non-nefarious routers and weakly connected nefarious routers.\par
However, classifier three was found to be more effective at identifying nefarious routers at the centre of the ROC curve, where specificity and sensitivity requirements were less stringent. This was due to a sympathetic increase in non-nefarious router PDA over baseline measurements, in turn due to background traffic being re-routed to these non-nefarious routers. Using PDA alone for identification, classifier two was unaffected by this sympathetic increase. Classifier three was therefore able to more effectively label nefarious nodes in cases where there was no overlap between nefarious and non-nefarious router PDA.\par
Following this, candidate optimisations to probe packet allocation and metric normalisation were analysed. Results using classifiers two and three on PDA data from network tomography, with and without proportional probe allocation (PPA), were presented in ROC curves. Improved classifier performance was observed in the Free and CPLEX topologies when using PPA. However, classifier two with unoptimised probing was found to perform worse than a random classification for false positive rates less than 0.5 in the Nobel topology. We anticipate this may have been due to background traffic not being routed through nefarious routers, thus causing their buffer queues to consist only of probe packets.\par
Additionally, performance of classifiers two and three in the Free topology was relatively unaffected by the use of PPA in network tomography. This was due to a higher portion of probe paths traversing a common router in the Free topology, causing this router's queue buffer to reach capacity and drop probe packets. Proportional allocation when sending probes therefore did not impact the number of probes received by the destination monitors in each probe path, thus nullifying any impacts from PPA.\par
The Cramér–Rao bound of both probing schemes in each topology was then calculated and contrasted against the observed performance of each classifier. The CRB was found to be very low in all cases, due to the number of probe paths required in each topology. However, the CRB was found to corroborate observed classifier performance, both between topologies and between probing schemes, over the same topology.\par
Finally, we analysed the impact of normalising PDA measurements with respect to the degree of each router. This was done to account for the contribution of incoming traffic to the size of each router's queue buffer. However, performance of classifiers two and three was found to be worse with this metric normalisation for every topology considered. We postulated that this was due to a router's degree being insufficient to account for the contribution of incoming traffic to the size of its queue buffer. We also discussed the possibility that the factors contributing to a router's queue buffer size are intrinsically related, and that no amount of data post-processing can better identify the contribution of nefarious delaying.